{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "52IREFHHSRo3"
   },
   "source": [
    "####Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBhJt5WWNdbB",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PxjsghtOTgTi"
   },
   "source": [
    "####Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g7Eg6-J6Srmx",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 150\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "template = 'keras_cifar10_trained_model{}.h5'\n",
    "model_names = [template.format(x) for x in range(1, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3e8ijcFgUGOz"
   },
   "source": [
    "####Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "PuV8mjlxSuUQ",
    "outputId": "2c71e31c-079b-4849-9aab-4d2968b16439",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_val = x_train[:10000]\n",
    "y_val = y_train[:10000]\n",
    "x_train = x_train[10000:]\n",
    "y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJ513OINXoBW"
   },
   "source": [
    "####Initialising all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IE-r2J9FN2BM",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 156,810\n",
      "Trainable params: 156,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "models = [0] * 9\n",
    "models[0] = keras.Sequential([\n",
    "    Conv2D(32, (5, 5), input_shape=x_train.shape[1:], activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (5, 5), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "print (models[0].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hN1zS5JuTLiq",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 58,506\n",
      "Trainable params: 58,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "models[1] = keras.Sequential([\n",
    "    Conv2D(32, (5, 5), input_shape=x_train.shape[1:], activation='relu'),\n",
    "    MaxPooling2D(pool_size=(3, 3)),\n",
    "    Conv2D(64, (5, 5), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(3, 3)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "print (models[1].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FLP5sLbCTLk1",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 167,562\n",
      "Trainable params: 167,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "models[2] = keras.Sequential([\n",
    "    Conv2D(32, (3, 3), input_shape=x_train.shape[1:], activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "print (models[2].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0ReP7dfTLoe",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 126,730\n",
      "Trainable params: 126,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "models[3] = keras.Sequential([\n",
    "    Conv2D(32, (3, 3), input_shape=x_train.shape[1:], activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "print (models[3].summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1hV8PPxCbeLE"
   },
   "source": [
    "####Compiling the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N1kpGy82N81P",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(1e-4)\n",
    "for i in range(4):\n",
    "    models[i].compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8XM-OMXvcK3E"
   },
   "source": [
    "####Creating callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NmHtdcTWecz4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_NjJ2VIwcJbE",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, History\n",
    "opt = keras.optimizers.Adam(1e-4)\n",
    "hist_temp = 'keras_cifar10_history{}.pkl'\n",
    "hist_names = [hist_temp.format(x) for x in range(1, 10)]\n",
    "early_stop = EarlyStopping(monitor='accuracy', min_delta=0, patience=20, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "history_callback = keras.callbacks.History    \n",
    "            \n",
    "class ModelCheckpointEnhanced(ModelCheckpoint):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Added arguments\n",
    "        self.callbacks_filepath = kwargs.pop('callbacks_filepath')\n",
    "        self.old_time = kwargs.pop('old_time')\n",
    "        self.start_time = time.time()\n",
    "        self.history = kwargs.pop('history') or {}\n",
    "        # self.epoch = []\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Run normal flow:\n",
    "        super().on_epoch_end(epoch,logs)\n",
    "        logs = logs or {}\n",
    "        # self.epoch.append(epoch)\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        # If a checkpoint was saved, save also the callback\n",
    "        filepath = self.callbacks_filepath.format(epoch=epoch + 1, **logs)\n",
    "        if self.epochs_since_last_save == 0:\n",
    "            if self.save_best_only:\n",
    "                current = logs.get(self.monitor)\n",
    "                if current == self.best:\n",
    "                    # Note, there might be some cases where the last statement will save on unwanted epochs.\n",
    "                    # However, in the usual case where your monitoring value space is continuous this is not likely\n",
    "                    save_history(filepath, self.history, (time.time() - self.start_time + self.old_time))\n",
    "            else:\n",
    "                save_history(filepath, self.history, (time.time() - self.start_time + self.old_time))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zg6hZLevcTOl"
   },
   "source": [
    "####Training and evaluating 1st 4 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vVGvL1ViOFI2",
    "outputId": "b05038f2-734b-4be5-cb07-c3b9b5ca2d7c",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_history (hist_path, history, total_time):\n",
    "    print ('Saving history at', hist_path, flush=True)\n",
    "    file_object = open (hist_path, 'wb')\n",
    "    pickle.dump (history, file_object)\n",
    "    pickle.dump (total_time, file_object)\n",
    "    file_object.close()\n",
    "    \n",
    "def load_history (hist_path):\n",
    "    print ('Loading history from', hist_path, flush=True)\n",
    "    file_object = open(hist_path, 'rb')\n",
    "    history = pickle.load(file_object)\n",
    "    total_time = pickle.load(file_object)\n",
    "    file_object.close()\n",
    "    return history, total_time\n",
    "             \n",
    "def process_history (prev_history, current_history):\n",
    "    for (k, v) in current_history.items():\n",
    "        if prev_history is not None:\n",
    "            v = prev_history[k] + v\n",
    "    return current_history\n",
    "\n",
    "def plot_history (history):\n",
    "    epochs = range(1, len(history['val_accuracy']) + 1)\n",
    "    plt.plot (epochs, history['val_accuracy'])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(len(epochs))\n",
    "    plt.show()\n",
    "\n",
    "def train_and_evaluate(model_id, use_saved):\n",
    "    print ('Current model = {}'.format(model_id + 1))\n",
    "    model = models[model_id]\n",
    "    model_path = os.path.join(save_dir, model_names[model_id])\n",
    "    hist_path = os.path.join(save_dir, hist_names[model_id])\n",
    "    filename = \"weights-improvement-{epoch:03d}-.hdf5\"\n",
    "    ckdir = os.path.join('checkpoints', '%d' % (model_id + 1))\n",
    "    if not os.path.isdir(ckdir):\n",
    "        os.makedirs(ckdir)\n",
    "    \n",
    "    filepath = os.path.join (ckdir, filename)\n",
    "    callbacks_filepath = os.path.join(ckdir, 'Historycallback.{epoch:03d}.pkl')\n",
    "    initial_epoch = 0\n",
    "    prev_time = 0\n",
    "    prev_history = None\n",
    "    cklist_full = os.listdir(ckdir)\n",
    "    cklist = []\n",
    "    histlist = []\n",
    "    if cklist_full :\n",
    "        cklist = [x for x in cklist_full if x[0] == 'w']\n",
    "        histlist = [x for x in cklist_full if x[0] == 'H']\n",
    "        cklist.sort()\n",
    "        cklist.pop()\n",
    "        histlist.pop()\n",
    "    if len(cklist) > len(histlist):\n",
    "        cklist.pop()\n",
    "    if use_saved:\n",
    "        if os.path.exists(model_path):\n",
    "            model = keras.models.load_model(model_path)\n",
    "            history, total_time = load_history(hist_path)\n",
    "            print ('Trained model loaded from {}', model_path)\n",
    "            loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "            print ('Time taken for model {} = {}'.format(model_id + 1, total_time))\n",
    "            print ('Loss = {}, Accuracy = {}'.format(loss, accuracy))\n",
    "            return history, loss, accuracy, total_time\n",
    "        elif cklist:\n",
    "            ckpath = os.path.join(ckdir, cklist[-1])\n",
    "            initial_epoch = [int(s) for s in cklist[-1].split('-') if s.isdigit()][0]\n",
    "            print ('initial_epoch = %d' % initial_epoch, flush=True)\n",
    "            model = keras.models.load_model(ckpath)\n",
    "            print ('Loaded checkpoint {} from {}'.format(initial_epoch, ckpath))\n",
    "            prev_history, prev_time = load_history(callbacks_filepath.format(epoch = initial_epoch))\n",
    "    \n",
    "    checkpoint = ModelCheckpointEnhanced(filepath, verbose=1, monitor='val_loss',\n",
    "                                         callbacks_to_save=history_callback, \n",
    "                                         callbacks_filepath=callbacks_filepath,\n",
    "                                         old_time=prev_time, history = prev_history\n",
    "                                         )        \n",
    "    callbacks_list = [early_stop, checkpoint]\n",
    "    start_time = time.time()\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, \n",
    "                        initial_epoch = initial_epoch,\n",
    "                        epochs=epochs, validation_data=(x_val, y_val), workers=4, \n",
    "                        shuffle=True, callbacks=callbacks_list)\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    total_time += prev_time\n",
    "\n",
    "    print ('Time taken for model {} = {}'.format(model_id + 1, total_time))\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print ('Loss = {}, Accuracy = {}'.format(loss, accuracy))\n",
    "    history = process_history (prev_history, history.history)\n",
    "    model.save(model_path)\n",
    "    save_history(hist_path, history, total_time)\n",
    "    print('Saved trained model at %s ' % model_path)\n",
    "    return history, loss, accuracy, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKLUjofzZl91",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model = 1\n",
      "Loading history from /home/satvik/Downloads/saved_models/keras_cifar10_history0.pkl\n",
      "Trained model loaded from {} /home/satvik/Downloads/saved_models/keras_cifar10_trained_model0.h5\n",
      "Time taken for model 1 = 129.26658844947815\n",
      "Loss = 1.7329203903198243, Accuracy = 0.3788999915122986\n",
      "Current model = 2\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2961 - accuracy: 0.1042\n",
      "Epoch 00001: saving model to checkpoints/2/weights-improvement-001-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.001.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2938 - accuracy: 0.1120 - val_loss: 2.2977 - val_accuracy: 0.1170\n",
      "Epoch 2/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2905 - accuracy: 0.1354\n",
      "Epoch 00002: saving model to checkpoints/2/weights-improvement-002-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.002.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2887 - accuracy: 0.1430 - val_loss: 2.2953 - val_accuracy: 0.1308\n",
      "Epoch 3/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2864 - accuracy: 0.1510\n",
      "Epoch 00003: saving model to checkpoints/2/weights-improvement-003-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.003.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2850 - accuracy: 0.1500 - val_loss: 2.2935 - val_accuracy: 0.1257\n",
      "Epoch 4/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2836 - accuracy: 0.1406\n",
      "Epoch 00004: saving model to checkpoints/2/weights-improvement-004-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.004.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2821 - accuracy: 0.1400 - val_loss: 2.2923 - val_accuracy: 0.1209\n",
      "Epoch 5/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2807 - accuracy: 0.1484\n",
      "Epoch 00005: saving model to checkpoints/2/weights-improvement-005-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.005.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2794 - accuracy: 0.1400 - val_loss: 2.2916 - val_accuracy: 0.1249\n",
      "Epoch 6/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2777 - accuracy: 0.1367\n",
      "Epoch 00006: saving model to checkpoints/2/weights-improvement-006-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.006.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2776 - accuracy: 0.1470 - val_loss: 2.2908 - val_accuracy: 0.1373\n",
      "Epoch 7/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2732 - accuracy: 0.1576\n",
      "Epoch 00007: saving model to checkpoints/2/weights-improvement-007-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.007.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2753 - accuracy: 0.1550 - val_loss: 2.2896 - val_accuracy: 0.1404\n",
      "Epoch 8/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2723 - accuracy: 0.1758\n",
      "Epoch 00008: saving model to checkpoints/2/weights-improvement-008-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.008.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2729 - accuracy: 0.1660 - val_loss: 2.2877 - val_accuracy: 0.1497\n",
      "Epoch 9/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2655 - accuracy: 0.1836\n",
      "Epoch 00009: saving model to checkpoints/2/weights-improvement-009-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.009.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2705 - accuracy: 0.1740 - val_loss: 2.2855 - val_accuracy: 0.1540\n",
      "Epoch 10/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2657 - accuracy: 0.1823\n",
      "Epoch 00010: saving model to checkpoints/2/weights-improvement-010-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.010.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2679 - accuracy: 0.1780 - val_loss: 2.2826 - val_accuracy: 0.1560\n",
      "Epoch 11/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2665 - accuracy: 0.1797\n",
      "Epoch 00011: saving model to checkpoints/2/weights-improvement-011-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.011.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2648 - accuracy: 0.1790 - val_loss: 2.2792 - val_accuracy: 0.1570\n",
      "Epoch 12/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2622 - accuracy: 0.1849\n",
      "Epoch 00012: saving model to checkpoints/2/weights-improvement-012-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.012.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2615 - accuracy: 0.1810 - val_loss: 2.2762 - val_accuracy: 0.1600\n",
      "Epoch 13/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2635 - accuracy: 0.1719\n",
      "Epoch 00013: saving model to checkpoints/2/weights-improvement-013-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.013.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2579 - accuracy: 0.1860 - val_loss: 2.2739 - val_accuracy: 0.1618\n",
      "Epoch 14/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2541 - accuracy: 0.1875\n",
      "Epoch 00014: saving model to checkpoints/2/weights-improvement-014-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.014.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2548 - accuracy: 0.1840 - val_loss: 2.2724 - val_accuracy: 0.1621\n",
      "Epoch 15/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2517 - accuracy: 0.1901\n",
      "Epoch 00015: saving model to checkpoints/2/weights-improvement-015-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.015.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2510 - accuracy: 0.1860 - val_loss: 2.2695 - val_accuracy: 0.1636\n",
      "Epoch 16/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2460 - accuracy: 0.1992\n",
      "Epoch 00016: saving model to checkpoints/2/weights-improvement-016-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.016.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2472 - accuracy: 0.1920 - val_loss: 2.2658 - val_accuracy: 0.1612\n",
      "Epoch 17/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2391 - accuracy: 0.1992\n",
      "Epoch 00017: saving model to checkpoints/2/weights-improvement-017-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.017.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2430 - accuracy: 0.1880 - val_loss: 2.2620 - val_accuracy: 0.1621\n",
      "Epoch 18/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2395 - accuracy: 0.1940\n",
      "Epoch 00018: saving model to checkpoints/2/weights-improvement-018-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.018.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2385 - accuracy: 0.1870 - val_loss: 2.2585 - val_accuracy: 0.1660\n",
      "Epoch 19/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2343 - accuracy: 0.2005\n",
      "Epoch 00019: saving model to checkpoints/2/weights-improvement-019-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.019.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2342 - accuracy: 0.1940 - val_loss: 2.2550 - val_accuracy: 0.1672\n",
      "Epoch 20/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2292 - accuracy: 0.1927\n",
      "Epoch 00020: saving model to checkpoints/2/weights-improvement-020-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.020.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2295 - accuracy: 0.1940 - val_loss: 2.2505 - val_accuracy: 0.1704\n",
      "Epoch 21/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2201 - accuracy: 0.1979\n",
      "Epoch 00021: saving model to checkpoints/2/weights-improvement-021-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.021.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2237 - accuracy: 0.1950 - val_loss: 2.2459 - val_accuracy: 0.1695\n",
      "Epoch 22/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2254 - accuracy: 0.1849\n",
      "Epoch 00022: saving model to checkpoints/2/weights-improvement-022-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.022.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2177 - accuracy: 0.1970 - val_loss: 2.2396 - val_accuracy: 0.1709\n",
      "Epoch 23/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2121 - accuracy: 0.1940\n",
      "Epoch 00023: saving model to checkpoints/2/weights-improvement-023-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.023.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2114 - accuracy: 0.2010 - val_loss: 2.2334 - val_accuracy: 0.1728\n",
      "Epoch 24/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2051 - accuracy: 0.2083\n",
      "Epoch 00024: saving model to checkpoints/2/weights-improvement-024-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.024.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2043 - accuracy: 0.2020 - val_loss: 2.2274 - val_accuracy: 0.1755\n",
      "Epoch 25/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1956 - accuracy: 0.1901\n",
      "Epoch 00025: saving model to checkpoints/2/weights-improvement-025-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.025.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1970 - accuracy: 0.2030 - val_loss: 2.2218 - val_accuracy: 0.1766\n",
      "Epoch 26/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1974 - accuracy: 0.1992\n",
      "Epoch 00026: saving model to checkpoints/2/weights-improvement-026-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.026.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1888 - accuracy: 0.2130 - val_loss: 2.2136 - val_accuracy: 0.1864\n",
      "Epoch 27/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1820 - accuracy: 0.2188\n",
      "Epoch 00027: saving model to checkpoints/2/weights-improvement-027-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.027.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1796 - accuracy: 0.2170 - val_loss: 2.2059 - val_accuracy: 0.1874\n",
      "Epoch 28/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1712 - accuracy: 0.2109\n",
      "Epoch 00028: saving model to checkpoints/2/weights-improvement-028-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.028.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1708 - accuracy: 0.2130 - val_loss: 2.1985 - val_accuracy: 0.1867\n",
      "Epoch 29/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1596 - accuracy: 0.2266\n",
      "Epoch 00029: saving model to checkpoints/2/weights-improvement-029-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.029.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1618 - accuracy: 0.2160 - val_loss: 2.1905 - val_accuracy: 0.1912\n",
      "Epoch 30/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1438 - accuracy: 0.2331\n",
      "Epoch 00030: saving model to checkpoints/2/weights-improvement-030-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.030.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1528 - accuracy: 0.2220 - val_loss: 2.1833 - val_accuracy: 0.1915\n",
      "Epoch 31/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1421 - accuracy: 0.2214\n",
      "Epoch 00031: saving model to checkpoints/2/weights-improvement-031-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.031.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1432 - accuracy: 0.2300 - val_loss: 2.1734 - val_accuracy: 0.1936\n",
      "Epoch 32/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1393 - accuracy: 0.2253\n",
      "Epoch 00032: saving model to checkpoints/2/weights-improvement-032-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.032.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1333 - accuracy: 0.2280 - val_loss: 2.1643 - val_accuracy: 0.1976\n",
      "Epoch 33/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1156 - accuracy: 0.2409\n",
      "Epoch 00033: saving model to checkpoints/2/weights-improvement-033-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.033.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1248 - accuracy: 0.2330 - val_loss: 2.1554 - val_accuracy: 0.1950\n",
      "Epoch 34/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1159 - accuracy: 0.2318\n",
      "Epoch 00034: saving model to checkpoints/2/weights-improvement-034-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.034.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1132 - accuracy: 0.2320 - val_loss: 2.1468 - val_accuracy: 0.2008\n",
      "Epoch 35/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1008 - accuracy: 0.2474\n",
      "Epoch 00035: saving model to checkpoints/2/weights-improvement-035-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.035.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1044 - accuracy: 0.2440 - val_loss: 2.1376 - val_accuracy: 0.2068\n",
      "Epoch 36/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.0896 - accuracy: 0.2526\n",
      "Epoch 00036: saving model to checkpoints/2/weights-improvement-036-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.036.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.0925 - accuracy: 0.2420 - val_loss: 2.1296 - val_accuracy: 0.2012\n",
      "Epoch 37/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.0764 - accuracy: 0.2474\n",
      "Epoch 00037: saving model to checkpoints/2/weights-improvement-037-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.037.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.0843 - accuracy: 0.2380 - val_loss: 2.1213 - val_accuracy: 0.2046\n",
      "Epoch 38/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.0798 - accuracy: 0.2474\n",
      "Epoch 00038: saving model to checkpoints/2/weights-improvement-038-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.038.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.0744 - accuracy: 0.2490 - val_loss: 2.1104 - val_accuracy: 0.2163\n",
      "Epoch 39/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.0595 - accuracy: 0.2578\n",
      "Epoch 00039: saving model to checkpoints/2/weights-improvement-039-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.039.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.0643 - accuracy: 0.2610 - val_loss: 2.1031 - val_accuracy: 0.2184\n",
      "Epoch 40/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.0516 - accuracy: 0.2734\n",
      "Epoch 00040: saving model to checkpoints/2/weights-improvement-040-.hdf5\n",
      "Saving history at checkpoints/2/Historycallback.040.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.0552 - accuracy: 0.2670 - val_loss: 2.0942 - val_accuracy: 0.2173\n",
      "Time taken for model 2 = 77.36724996566772\n",
      "Loss = 2.0984892084121705, Accuracy = 0.21230000257492065\n",
      "Saving history at /home/satvik/Downloads/saved_models/keras_cifar10_history1.pkl\n",
      "Saved trained model at /home/satvik/Downloads/saved_models/keras_cifar10_trained_model1.h5 \n",
      "Current model = 3\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.3017 - accuracy: 0.0951\n",
      "Epoch 00001: saving model to checkpoints/3/weights-improvement-001-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.001.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.3001 - accuracy: 0.1010 - val_loss: 2.2981 - val_accuracy: 0.1509\n",
      "Epoch 2/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2869 - accuracy: 0.1732\n",
      "Epoch 00002: saving model to checkpoints/3/weights-improvement-002-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.002.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2869 - accuracy: 0.1700 - val_loss: 2.2903 - val_accuracy: 0.1614\n",
      "Epoch 3/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2729 - accuracy: 0.1914\n",
      "Epoch 00003: saving model to checkpoints/3/weights-improvement-003-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.003.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2729 - accuracy: 0.1950 - val_loss: 2.2792 - val_accuracy: 0.1682\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2555 - accuracy: 0.1901\n",
      "Epoch 00004: saving model to checkpoints/3/weights-improvement-004-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.004.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2551 - accuracy: 0.1940 - val_loss: 2.2628 - val_accuracy: 0.1699\n",
      "Epoch 5/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2302 - accuracy: 0.2109\n",
      "Epoch 00005: saving model to checkpoints/3/weights-improvement-005-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.005.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2341 - accuracy: 0.2040 - val_loss: 2.2416 - val_accuracy: 0.1734\n",
      "Epoch 6/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2092 - accuracy: 0.1979\n",
      "Epoch 00006: saving model to checkpoints/3/weights-improvement-006-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.006.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.2086 - accuracy: 0.2030 - val_loss: 2.2154 - val_accuracy: 0.1755\n",
      "Epoch 7/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1831 - accuracy: 0.1992\n",
      "Epoch 00007: saving model to checkpoints/3/weights-improvement-007-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.007.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1784 - accuracy: 0.2070 - val_loss: 2.1870 - val_accuracy: 0.1793\n",
      "Epoch 8/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1531 - accuracy: 0.2031\n",
      "Epoch 00008: saving model to checkpoints/3/weights-improvement-008-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.008.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1462 - accuracy: 0.2070 - val_loss: 2.1578 - val_accuracy: 0.1825\n",
      "Epoch 9/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1179 - accuracy: 0.2161\n",
      "Epoch 00009: saving model to checkpoints/3/weights-improvement-009-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.009.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.1147 - accuracy: 0.2210 - val_loss: 2.1277 - val_accuracy: 0.2025\n",
      "Epoch 10/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.0890 - accuracy: 0.2500\n",
      "Epoch 00010: saving model to checkpoints/3/weights-improvement-010-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.010.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.0829 - accuracy: 0.2620 - val_loss: 2.0998 - val_accuracy: 0.2248\n",
      "Epoch 11/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.0650 - accuracy: 0.2734\n",
      "Epoch 00011: saving model to checkpoints/3/weights-improvement-011-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.011.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.0537 - accuracy: 0.2750 - val_loss: 2.0734 - val_accuracy: 0.2437\n",
      "Epoch 12/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.0425 - accuracy: 0.2917\n",
      "Epoch 00012: saving model to checkpoints/3/weights-improvement-012-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.012.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.0245 - accuracy: 0.2990 - val_loss: 2.0494 - val_accuracy: 0.2539\n",
      "Epoch 13/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.9913 - accuracy: 0.3216\n",
      "Epoch 00013: saving model to checkpoints/3/weights-improvement-013-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.013.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.9990 - accuracy: 0.3200 - val_loss: 2.0249 - val_accuracy: 0.2779\n",
      "Epoch 14/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.9678 - accuracy: 0.3529\n",
      "Epoch 00014: saving model to checkpoints/3/weights-improvement-014-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.014.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.9724 - accuracy: 0.3490 - val_loss: 2.0060 - val_accuracy: 0.2912\n",
      "Epoch 15/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.9553 - accuracy: 0.3607\n",
      "Epoch 00015: saving model to checkpoints/3/weights-improvement-015-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.015.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.9499 - accuracy: 0.3540 - val_loss: 1.9814 - val_accuracy: 0.3049\n",
      "Epoch 16/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.9120 - accuracy: 0.3750\n",
      "Epoch 00016: saving model to checkpoints/3/weights-improvement-016-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.016.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.9246 - accuracy: 0.3690 - val_loss: 1.9599 - val_accuracy: 0.3100\n",
      "Epoch 17/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.9001 - accuracy: 0.3789\n",
      "Epoch 00017: saving model to checkpoints/3/weights-improvement-017-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.017.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.8974 - accuracy: 0.3780 - val_loss: 1.9431 - val_accuracy: 0.3120\n",
      "Epoch 18/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.8846 - accuracy: 0.3633\n",
      "Epoch 00018: saving model to checkpoints/3/weights-improvement-018-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.018.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.8739 - accuracy: 0.3780 - val_loss: 1.9221 - val_accuracy: 0.3241\n",
      "Epoch 19/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.8450 - accuracy: 0.4049\n",
      "Epoch 00019: saving model to checkpoints/3/weights-improvement-019-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.019.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.8486 - accuracy: 0.4010 - val_loss: 1.9060 - val_accuracy: 0.3264\n",
      "Epoch 20/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.8354 - accuracy: 0.3893\n",
      "Epoch 00020: saving model to checkpoints/3/weights-improvement-020-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.020.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.8254 - accuracy: 0.3970 - val_loss: 1.8880 - val_accuracy: 0.3291\n",
      "Epoch 21/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.8123 - accuracy: 0.4076\n",
      "Epoch 00021: saving model to checkpoints/3/weights-improvement-021-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.021.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.8063 - accuracy: 0.4100 - val_loss: 1.8721 - val_accuracy: 0.3350\n",
      "Epoch 22/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.7872 - accuracy: 0.4076\n",
      "Epoch 00022: saving model to checkpoints/3/weights-improvement-022-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.022.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.7854 - accuracy: 0.4160 - val_loss: 1.8586 - val_accuracy: 0.3361\n",
      "Epoch 23/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.7752 - accuracy: 0.4010\n",
      "Epoch 00023: saving model to checkpoints/3/weights-improvement-023-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.023.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.7660 - accuracy: 0.4090 - val_loss: 1.8503 - val_accuracy: 0.3375\n",
      "Epoch 24/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.7299 - accuracy: 0.4271\n",
      "Epoch 00024: saving model to checkpoints/3/weights-improvement-024-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.024.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.7471 - accuracy: 0.4230 - val_loss: 1.8367 - val_accuracy: 0.3427\n",
      "Epoch 25/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.7437 - accuracy: 0.4167\n",
      "Epoch 00025: saving model to checkpoints/3/weights-improvement-025-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.025.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.7305 - accuracy: 0.4300 - val_loss: 1.8226 - val_accuracy: 0.3497\n",
      "Epoch 26/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.7127 - accuracy: 0.4401\n",
      "Epoch 00026: saving model to checkpoints/3/weights-improvement-026-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.026.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.7182 - accuracy: 0.4350 - val_loss: 1.8161 - val_accuracy: 0.3517\n",
      "Epoch 27/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.7072 - accuracy: 0.4310\n",
      "Epoch 00027: saving model to checkpoints/3/weights-improvement-027-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.027.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.7035 - accuracy: 0.4430 - val_loss: 1.8047 - val_accuracy: 0.3516\n",
      "Epoch 28/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6888 - accuracy: 0.4453\n",
      "Epoch 00028: saving model to checkpoints/3/weights-improvement-028-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.028.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.6829 - accuracy: 0.4440 - val_loss: 1.8040 - val_accuracy: 0.3554\n",
      "Epoch 29/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6885 - accuracy: 0.4414\n",
      "Epoch 00029: saving model to checkpoints/3/weights-improvement-029-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.029.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.6736 - accuracy: 0.4480 - val_loss: 1.7894 - val_accuracy: 0.3605\n",
      "Epoch 30/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6586 - accuracy: 0.4635\n",
      "Epoch 00030: saving model to checkpoints/3/weights-improvement-030-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.030.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.6550 - accuracy: 0.4620 - val_loss: 1.7805 - val_accuracy: 0.3665\n",
      "Epoch 31/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6332 - accuracy: 0.4740\n",
      "Epoch 00031: saving model to checkpoints/3/weights-improvement-031-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.031.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.6420 - accuracy: 0.4640 - val_loss: 1.7726 - val_accuracy: 0.3667\n",
      "Epoch 32/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6301 - accuracy: 0.4440\n",
      "Epoch 00032: saving model to checkpoints/3/weights-improvement-032-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.032.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.6317 - accuracy: 0.4570 - val_loss: 1.7671 - val_accuracy: 0.3709\n",
      "Epoch 33/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6201 - accuracy: 0.4583\n",
      "Epoch 00033: saving model to checkpoints/3/weights-improvement-033-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.033.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.6170 - accuracy: 0.4590 - val_loss: 1.7658 - val_accuracy: 0.3693\n",
      "Epoch 34/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.5974 - accuracy: 0.4661\n",
      "Epoch 00034: saving model to checkpoints/3/weights-improvement-034-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.034.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.6070 - accuracy: 0.4650 - val_loss: 1.7555 - val_accuracy: 0.3728\n",
      "Epoch 35/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6059 - accuracy: 0.4688\n",
      "Epoch 00035: saving model to checkpoints/3/weights-improvement-035-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.035.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.5956 - accuracy: 0.4680 - val_loss: 1.7510 - val_accuracy: 0.3710\n",
      "Epoch 36/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.5917 - accuracy: 0.4714\n",
      "Epoch 00036: saving model to checkpoints/3/weights-improvement-036-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.036.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.5855 - accuracy: 0.4720 - val_loss: 1.7452 - val_accuracy: 0.3780\n",
      "Epoch 37/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.5630 - accuracy: 0.4883\n",
      "Epoch 00037: saving model to checkpoints/3/weights-improvement-037-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.037.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.5724 - accuracy: 0.4860 - val_loss: 1.7404 - val_accuracy: 0.3783\n",
      "Epoch 38/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.5726 - accuracy: 0.4857\n",
      "Epoch 00038: saving model to checkpoints/3/weights-improvement-038-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.038.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.5637 - accuracy: 0.4840 - val_loss: 1.7353 - val_accuracy: 0.3795\n",
      "Epoch 39/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.5346 - accuracy: 0.4844\n",
      "Epoch 00039: saving model to checkpoints/3/weights-improvement-039-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.039.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.5523 - accuracy: 0.4810 - val_loss: 1.7335 - val_accuracy: 0.3787\n",
      "Epoch 40/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.5429 - accuracy: 0.4909\n",
      "Epoch 00040: saving model to checkpoints/3/weights-improvement-040-.hdf5\n",
      "Saving history at checkpoints/3/Historycallback.040.pkl\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.5424 - accuracy: 0.4840 - val_loss: 1.7247 - val_accuracy: 0.3848\n",
      "Time taken for model 3 = 91.28589153289795\n",
      "Loss = 1.7314680366516113, Accuracy = 0.3828999996185303\n",
      "Saving history at /home/satvik/Downloads/saved_models/keras_cifar10_history2.pkl\n",
      "Saved trained model at /home/satvik/Downloads/saved_models/keras_cifar10_trained_model2.h5 \n",
      "Current model = 4\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.3012 - accuracy: 0.1081\n",
      "Epoch 00001: saving model to checkpoints/4/weights-improvement-001-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.001.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.3037 - accuracy: 0.1020 - val_loss: 2.3035 - val_accuracy: 0.1009\n",
      "Epoch 2/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2899 - accuracy: 0.1393\n",
      "Epoch 00002: saving model to checkpoints/4/weights-improvement-002-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.002.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.2948 - accuracy: 0.1320 - val_loss: 2.2991 - val_accuracy: 0.1324\n",
      "Epoch 3/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2908 - accuracy: 0.1667\n",
      "Epoch 00003: saving model to checkpoints/4/weights-improvement-003-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.003.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.2879 - accuracy: 0.1760 - val_loss: 2.2951 - val_accuracy: 0.1603\n",
      "Epoch 4/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2805 - accuracy: 0.1849\n",
      "Epoch 00004: saving model to checkpoints/4/weights-improvement-004-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.004.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.2803 - accuracy: 0.1850 - val_loss: 2.2899 - val_accuracy: 0.1637\n",
      "Epoch 5/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2757 - accuracy: 0.1823\n",
      "Epoch 00005: saving model to checkpoints/4/weights-improvement-005-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.005.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.2709 - accuracy: 0.1930 - val_loss: 2.2804 - val_accuracy: 0.1684\n",
      "Epoch 6/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2649 - accuracy: 0.1966\n",
      "Epoch 00006: saving model to checkpoints/4/weights-improvement-006-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.006.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.2576 - accuracy: 0.2080 - val_loss: 2.2683 - val_accuracy: 0.1735\n",
      "Epoch 7/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2446 - accuracy: 0.2031\n",
      "Epoch 00007: saving model to checkpoints/4/weights-improvement-007-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.007.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.2433 - accuracy: 0.2120 - val_loss: 2.2534 - val_accuracy: 0.1828\n",
      "Epoch 8/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.2198 - accuracy: 0.2240\n",
      "Epoch 00008: saving model to checkpoints/4/weights-improvement-008-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.008.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.2223 - accuracy: 0.2140 - val_loss: 2.2341 - val_accuracy: 0.1778\n",
      "Epoch 9/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1974 - accuracy: 0.2109\n",
      "Epoch 00009: saving model to checkpoints/4/weights-improvement-009-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.009.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.1971 - accuracy: 0.2140 - val_loss: 2.2067 - val_accuracy: 0.1861\n",
      "Epoch 10/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1839 - accuracy: 0.2070\n",
      "Epoch 00010: saving model to checkpoints/4/weights-improvement-010-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.010.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.1707 - accuracy: 0.2250 - val_loss: 2.1782 - val_accuracy: 0.1925\n",
      "Epoch 11/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1421 - accuracy: 0.2279\n",
      "Epoch 00011: saving model to checkpoints/4/weights-improvement-011-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.011.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.1405 - accuracy: 0.2290 - val_loss: 2.1530 - val_accuracy: 0.1895\n",
      "Epoch 12/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.1100 - accuracy: 0.2318\n",
      "Epoch 00012: saving model to checkpoints/4/weights-improvement-012-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.012.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.1100 - accuracy: 0.2300 - val_loss: 2.1308 - val_accuracy: 0.1909\n",
      "Epoch 13/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.0848 - accuracy: 0.2318\n",
      "Epoch 00013: saving model to checkpoints/4/weights-improvement-013-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.013.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.0786 - accuracy: 0.2320 - val_loss: 2.0976 - val_accuracy: 0.2086\n",
      "Epoch 14/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.0445 - accuracy: 0.2578\n",
      "Epoch 00014: saving model to checkpoints/4/weights-improvement-014-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.014.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.0477 - accuracy: 0.2500 - val_loss: 2.0682 - val_accuracy: 0.2143\n",
      "Epoch 15/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 2.0325 - accuracy: 0.2591\n",
      "Epoch 00015: saving model to checkpoints/4/weights-improvement-015-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.015.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.0182 - accuracy: 0.2650 - val_loss: 2.0444 - val_accuracy: 0.2216\n",
      "Epoch 16/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.9956 - accuracy: 0.2799\n",
      "Epoch 00016: saving model to checkpoints/4/weights-improvement-016-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.016.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.9900 - accuracy: 0.2810 - val_loss: 2.0236 - val_accuracy: 0.2411\n",
      "Epoch 17/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.9766 - accuracy: 0.3125\n",
      "Epoch 00017: saving model to checkpoints/4/weights-improvement-017-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.017.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.9678 - accuracy: 0.3050 - val_loss: 1.9981 - val_accuracy: 0.2595\n",
      "Epoch 18/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.9449 - accuracy: 0.3294\n",
      "Epoch 00018: saving model to checkpoints/4/weights-improvement-018-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.018.pkl\n",
      "1000/1000 [==============================] - 4s 4ms/sample - loss: 1.9376 - accuracy: 0.3350 - val_loss: 1.9752 - val_accuracy: 0.2859\n",
      "Epoch 19/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.8987 - accuracy: 0.3672\n",
      "Epoch 00019: saving model to checkpoints/4/weights-improvement-019-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.019.pkl\n",
      "1000/1000 [==============================] - 4s 4ms/sample - loss: 1.9138 - accuracy: 0.3580 - val_loss: 1.9657 - val_accuracy: 0.2815\n",
      "Epoch 20/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.9080 - accuracy: 0.3385\n",
      "Epoch 00020: saving model to checkpoints/4/weights-improvement-020-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.020.pkl\n",
      "1000/1000 [==============================] - 4s 4ms/sample - loss: 1.8988 - accuracy: 0.3440 - val_loss: 1.9461 - val_accuracy: 0.2829\n",
      "Epoch 21/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.8927 - accuracy: 0.3503\n",
      "Epoch 00021: saving model to checkpoints/4/weights-improvement-021-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.021.pkl\n",
      "1000/1000 [==============================] - 4s 4ms/sample - loss: 1.8811 - accuracy: 0.3440 - val_loss: 1.9302 - val_accuracy: 0.2944\n",
      "Epoch 22/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.8482 - accuracy: 0.3633\n",
      "Epoch 00022: saving model to checkpoints/4/weights-improvement-022-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.022.pkl\n",
      "1000/1000 [==============================] - 4s 4ms/sample - loss: 1.8507 - accuracy: 0.3580 - val_loss: 1.9117 - val_accuracy: 0.3024\n",
      "Epoch 23/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.8384 - accuracy: 0.3672\n",
      "Epoch 00023: saving model to checkpoints/4/weights-improvement-023-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.023.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.8349 - accuracy: 0.3740 - val_loss: 1.9042 - val_accuracy: 0.3127\n",
      "Epoch 24/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.8083 - accuracy: 0.3919\n",
      "Epoch 00024: saving model to checkpoints/4/weights-improvement-024-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.024.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.8171 - accuracy: 0.3700 - val_loss: 1.8917 - val_accuracy: 0.3000\n",
      "Epoch 25/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.8117 - accuracy: 0.3698\n",
      "Epoch 00025: saving model to checkpoints/4/weights-improvement-025-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.025.pkl\n",
      "1000/1000 [==============================] - 4s 4ms/sample - loss: 1.8047 - accuracy: 0.3750 - val_loss: 1.8842 - val_accuracy: 0.3100\n",
      "Epoch 26/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.7891 - accuracy: 0.3815\n",
      "Epoch 00026: saving model to checkpoints/4/weights-improvement-026-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.026.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.7901 - accuracy: 0.3810 - val_loss: 1.8703 - val_accuracy: 0.3130\n",
      "Epoch 27/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.7939 - accuracy: 0.3815\n",
      "Epoch 00027: saving model to checkpoints/4/weights-improvement-027-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.027.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.7802 - accuracy: 0.3900 - val_loss: 1.8576 - val_accuracy: 0.3218\n",
      "Epoch 28/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.7768 - accuracy: 0.3893\n",
      "Epoch 00028: saving model to checkpoints/4/weights-improvement-028-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.028.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.7622 - accuracy: 0.3910 - val_loss: 1.8472 - val_accuracy: 0.3229\n",
      "Epoch 29/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.7405 - accuracy: 0.3971\n",
      "Epoch 00029: saving model to checkpoints/4/weights-improvement-029-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.029.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.7435 - accuracy: 0.3970 - val_loss: 1.8475 - val_accuracy: 0.3243\n",
      "Epoch 30/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.7361 - accuracy: 0.4062\n",
      "Epoch 00030: saving model to checkpoints/4/weights-improvement-030-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.030.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.7334 - accuracy: 0.4050 - val_loss: 1.8395 - val_accuracy: 0.3277\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.7186 - accuracy: 0.4115\n",
      "Epoch 00031: saving model to checkpoints/4/weights-improvement-031-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.031.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.7224 - accuracy: 0.4120 - val_loss: 1.8307 - val_accuracy: 0.3271\n",
      "Epoch 32/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.7227 - accuracy: 0.3958\n",
      "Epoch 00032: saving model to checkpoints/4/weights-improvement-032-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.032.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.7145 - accuracy: 0.4030 - val_loss: 1.8227 - val_accuracy: 0.3314\n",
      "Epoch 33/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6809 - accuracy: 0.4245\n",
      "Epoch 00033: saving model to checkpoints/4/weights-improvement-033-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.033.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.7042 - accuracy: 0.4110 - val_loss: 1.8279 - val_accuracy: 0.3248\n",
      "Epoch 34/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6735 - accuracy: 0.4128\n",
      "Epoch 00034: saving model to checkpoints/4/weights-improvement-034-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.034.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.6935 - accuracy: 0.4000 - val_loss: 1.8077 - val_accuracy: 0.3399\n",
      "Epoch 35/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6781 - accuracy: 0.4258\n",
      "Epoch 00035: saving model to checkpoints/4/weights-improvement-035-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.035.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.6787 - accuracy: 0.4140 - val_loss: 1.8014 - val_accuracy: 0.3392\n",
      "Epoch 36/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6725 - accuracy: 0.4284\n",
      "Epoch 00036: saving model to checkpoints/4/weights-improvement-036-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.036.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.6717 - accuracy: 0.4250 - val_loss: 1.8019 - val_accuracy: 0.3387\n",
      "Epoch 37/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6475 - accuracy: 0.4258\n",
      "Epoch 00037: saving model to checkpoints/4/weights-improvement-037-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.037.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.6581 - accuracy: 0.4260 - val_loss: 1.7947 - val_accuracy: 0.3436\n",
      "Epoch 38/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6471 - accuracy: 0.4310\n",
      "Epoch 00038: saving model to checkpoints/4/weights-improvement-038-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.038.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.6504 - accuracy: 0.4330 - val_loss: 1.7876 - val_accuracy: 0.3475\n",
      "Epoch 39/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6516 - accuracy: 0.4271\n",
      "Epoch 00039: saving model to checkpoints/4/weights-improvement-039-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.039.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.6447 - accuracy: 0.4260 - val_loss: 1.7835 - val_accuracy: 0.3480\n",
      "Epoch 40/40\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 1.6236 - accuracy: 0.4271\n",
      "Epoch 00040: saving model to checkpoints/4/weights-improvement-040-.hdf5\n",
      "Saving history at checkpoints/4/Historycallback.040.pkl\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.6312 - accuracy: 0.4320 - val_loss: 1.7786 - val_accuracy: 0.3506\n",
      "Time taken for model 4 = 117.86604404449463\n",
      "Loss = 1.780084848213196, Accuracy = 0.34700000286102295\n",
      "Saving history at /home/satvik/Downloads/saved_models/keras_cifar10_history3.pkl\n",
      "Saved trained model at /home/satvik/Downloads/saved_models/keras_cifar10_trained_model3.h5 \n"
     ]
    }
   ],
   "source": [
    "history_list = [0] * 9\n",
    "training_data = [0] * 9\n",
    "\n",
    "for i in range (4):\n",
    "    history, loss, accuracy, time_taken = train_and_evaluate(i, use_saved=True)\n",
    "    history_list[i] = history\n",
    "    data_dict = {'loss':loss, 'accuracy':accuracy, 'time_taken':time_taken}\n",
    "    training_data[i] = data_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 1\n",
      "{'loss': 1.7329203903198243, 'accuracy': 0.3789, 'time_taken': 129.26658844947815}\n",
      "Model: 2\n",
      "{'loss': 2.0984892084121705, 'accuracy': 0.2123, 'time_taken': 77.36724996566772}\n",
      "Model: 3\n",
      "{'loss': 1.7314680366516113, 'accuracy': 0.3829, 'time_taken': 91.28589153289795}\n",
      "Model: 4\n",
      "{'loss': 1.780084848213196, 'accuracy': 0.347, 'time_taken': 117.86604404449463}\n"
     ]
    }
   ],
   "source": [
    "for i in range (4):\n",
    "    print ('Model:', i + 1)\n",
    "    print (training_data[i])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "A3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
